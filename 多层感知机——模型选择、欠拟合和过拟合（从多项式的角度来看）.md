## 模型选择、欠拟合和过拟合（从多项式的角度来看）

> 有则寓言故事：地主家的傻儿子学写字，第一天学写“一”，。第二天学写“二”，第三天学写“三”，然后就把教书先生请走了，认为自己已经学会写字了，次日，家里来了一位叫“万百千”的客人，地主为了炫耀傻儿子的材质，让他写客人的名字。傻儿子在书房里写了两个小时还没出来，地主和客人进去看究竟，发现傻儿子在纸上画了很多横线，呼喊着“太多了，我写不完”。

上文的寓言故事里，地主家的傻儿子错误的提取了数字的书写方法，闹了很大的笑话。数字有很多的规则，如用来量级的个十百千，以及从0-9的十个数字，但是由于地主家的儿子只学了三个样本，所以他把自己看似正确的规律用到新的问题上时，就发现明显关系的不成立。

这种在训练集上拟合的效果比潜在分布的效果更接近的情况称为*过拟合*（overfitting），用于对抗过拟合的方法称为*正则化*（regularization），下面我们来看看一个多项式回归的例子，并切身的理解过拟合的后果，最后进行系统的总结。

### 多项式回归

#### 生成数据集

$$
y = 5 + 1.2x - 3.4\frac{x^2}{2!} + 5.6 \frac{x^3}{3!} + \epsilon \text{ where }
\epsilon \sim \mathcal{N}(0, 0.1^2).
$$



噪声$\epsilon$服从均值为0且标准差为0.1的正态分布，为了避免梯度或损失的变化太大，我们在对应次幂下增设了他的阶乘进行做比，test和train各100各样本

```python
#这一块我们生成一个训练标签y，噪声服从N(0,0.1^2)的正态分布
max_degree=20#多项式的最大系数
n_train,n_test=100,100#训练和测试数据集大小
true_w=np.zeros(max_degree)#给参数系数分配大量的空间
true_w[0:4]=np.array([5,1.2,-3.4,5.6])#我们只给常数，和1，2，3次幂分配系数

features = np.random.normal(size=(n_train+n_test,1))#features的前100元素是train数据集
np.random.shuffle(features)
poly_features=np.power(features,np.arange(max_degree).reshape(1,-1))#power是求幂的,这一步把xi变成了x^n,把一个向量转变成了带多项式的矩阵
for i in range(max_degree):
    poly_features[:,i]/=math.gamma(i+1)# gamma(n)=(n-1)!
#labels维度：(n_train+n_test,)
labels=np.dot(poly_features,true_w)#把系数和幂次进行乘积
labels+=np.random.normal(scale=0.1,size=labels.shape)
```

上边我们要注意poly_features=np.power(features,np.arange(max_degree).reshape(1,-1)，这一步把x变成了一个列20的多项式，都是x 的幂次.但是np数组不能用到torch里头，我们得转换下。

```python
# NumPy ndarray转换为tensor
true_w, features, poly_features, labels = [torch.tensor(x, dtype=
    torch.float32) for x in [true_w, features, poly_features, labels]]

features[:2], poly_features[:2, :], labels[:2]
```



#### 对模型进行训练测试

首先实现一个定义损失的函数：

```python
#评估模型的损失
def evaluate_loss(net,data_iter,loss):#@save
    metric=d2l.Accumulator(2)#损失的总和，样本数
    for X,y in data_iter:
        out = net(X)#获得对于特征的预测
        y = y.reshape(out.shape)
        l=loss(out,y)
        metric.add(l.sum(),l.numel())
    return metric[0]/metric[1]
```

定义训练函数：

```python
#定义训练函数
def train(train_features,test_features,train_labels,test_labels,num_epochs=400):
    loss=nn.MSELoss(reduction='none')#均方误差
    input_shape=train_features.shape[-1]#-1代表最后一个维度
    #我们不设置偏置b，因为多项式的常数项可以被视为偏置b
    net=nn.Sequential(nn.Linear(input_shape,1,bias=False))
    batch_size=min(10,train_labels.shape[0])#迭代器里的特征可能不够十，考虑下边界情况
    train_iter=d2l.load_array((train_features,train_labels.reshape(-1,1)),batch_size)
    test_iter=d2l.load_array((test_features,test_labels.reshape(-1,1)),batch_size,is_train=False)
    trainer=torch.optim.SGD(net.parameters(),lr=0.01)#这里的net.parameters代表着什么？需要思考、
    animator = d2l.Animator(xlabel='epoch',ylabel='loss',yscale='log',
                           xlim=[1,num_epochs],ylim=[1e-3,1e2],
                           legend=['train','test'])
    for epoch in range(num_epochs):
        d2l.train_epoch_ch3(net,train_iter,loss,trainer)
        if epoch ==0 or (epoch+1)%20==0:
             animator.add(epoch + 1, (evaluate_loss(net, train_iter, loss),
                                     evaluate_loss(net, test_iter, loss)))
    print('weight',net[0].weight.data.numpy())
```

你不能说这一块有多难，需要调用的函数稍微了解下就行，还是得以后多写，不能急功近利。



#### 准备工作做好，我们来看看，给参数不同的情况下，到底会有啥效果。

第一次，我们把正确的，需要对齐的维度给他，结果令人满意，该模型降低了训练和测试损失，参数也接近真实的$w = [5, 1.2, -3.4, 5.6]$

```python
# 从多项式特征中选择前4个维度，即1,x,x^2/2!,x^3/3!
train(poly_features[:n_train, :4], poly_features[n_train:, :4],
      labels[:n_train], labels[n_train:])
>>weight: [[ 5.000446   1.1925726 -3.3994446  5.613429 ]]
```



![../_images/output_underfit-overfit_ec26bd_68_1.svg](C:\Users\裴英豪\Desktop\思维导图总结\第二个月\深度学习笔记\source\inputs=4.svg)

第二次，只给常数和x维度的，我们能看到欠拟合的效果(btw,我感觉他很像一种直男缺根弦的思维）:



```python
# 从多项式特征中选择前2个维度，即1和x
train(poly_features[:n_train, :2], poly_features[n_train:, :2],
      labels[:n_train], labels[n_train:])
>>weight: [[3.3861537 3.623168 ]]
```



![../_images/output_underfit-overfit_ec26bd_83_1.svg](C:\Users\裴英豪\Desktop\思维导图总结\第二个月\深度学习笔记\source\inputs=2.svg)

第三次，高阶多项式拟合，我们选择所有的维度，但是哪些高得维度只是噪声带来的错误信息，我们可以看到复杂的模型很容易受到训练数据中噪声的影响。虽然训练损失可以有效地降低，但测试损失依然很高。证明：复杂模型对数据造成了过拟合。

```python
# 从多项式特征中选取所有维度
train(poly_features[:n_train, :], poly_features[n_train:, :],
      labels[:n_train], labels[n_train:], num_epochs=1500)
```

![1684489003708](C:\Users\裴英豪\Desktop\思维导图总结\第二个月\深度学习笔记\source\inputs=20.png)



> ### 对泛化误差的一个简单引入
>
> 我们引入两个误差：训练误差和泛化误差。 *训练误差*（training error）是指， 模型在训练数据集上计算得到的误差。 *泛化误差*（generalization error）是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。
>
> 问题是，我们永远不能准确地计算出泛化误差。 这是因为无限多的数据样本是一个虚构的对象。 在实际中，我们只能通过将模型应用于一个独立的测试集来估计泛化误差， 该测试集由随机选取的、未曾在训练集中出现的数据样本构成。
>
> 这里是个很简单的例子：你要去考数学一，你肯定有复习的好的，复习的不好的，考试的最后目的是要检测你的所有知识水平，如果你只做自己会做的题，你的平常练习正确率很高，但是他出题量有限。如果恰好出的和你会的重叠了，你有更小的测试误差，但这并不反映你的水平。而如果你自己学习的很多，各个模块的题都做，最后取得了和你平常差不多的结果，这是一个比较理想的情况。
>
> 但是我们要相信，通过不断地练习（训练training），我们最后都能在考试（测试test）里取得好成绩，可以被认为，这就是**训练误差会收敛到泛化误差**。

### 模型选择

#### 模型复杂性

> 当我们有简单的模型和大量的数据时，我们期望泛化误差与训练误差相近。 当我们有更复杂的模型和更少的样本时，我们预计训练误差会下降，但泛化误差会增大。 模型复杂性由什么构成是一个复杂的问题。 一个模型是否能很好地泛化取决于很多因素。 例如，具有更多参数的模型可能被认为更复杂， 参数有更大取值范围的模型可能更为复杂。 通常对于神经网络，我们认为需要更多训练迭代的模型比较复杂， 而需要*早停*（early stopping）的模型（即较少训练迭代周期）就不那么复杂。

一个很大的，很精确的在给定的田野上剥苞米的机器一定是缺乏泛用性的，一个模型亦是如此，总结既是：

1. 可调整参数的数量。当可调整参数的数量（有时称为*自由度*）很大时，模型往往更容易过拟合。
2. 参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。
3. 训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。



#### 验证集

由于数据的缺失，我们很少能有充足的数据对每一轮数据都采用全新的数据集，所以我们引入验证集（validation set）用来监测模型的泛化能力，我们希望的是验证集不会被用来决定参数，但是验证数据集和测试数据集的边界十分模糊，我们可以认为验证集给的是准确度。

#### K折交叉验证（k-fold cross validation）

把数据集分成k个包（这里以6为例），分别进行六次试验，第一次用第一个包作为验证集，第二次第二个包，以此类推。

![img](C:\Users\裴英豪\Desktop\思维导图总结\第二个月\深度学习笔记\source\k-fold cross validation)